{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feynman_GNN_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RlBYllxQvOsORtTreg4p8_Ni8iVLJl5v",
      "authorship_tag": "ABX9TyOmHpqWuytJi1KHOygIwWlw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71a7962e314f4e0db544fc607af67168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6bf4439f0b3a47a79544ab47cf0450ee",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49f8212a977b493896c0ffb037b34277",
              "IPY_MODEL_86b2d8f760e64156975bdb557ea88119",
              "IPY_MODEL_1ba91d9b442a43fd88d34eec60cdbe77"
            ]
          }
        },
        "6bf4439f0b3a47a79544ab47cf0450ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "49f8212a977b493896c0ffb037b34277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87602462cac54b128fb01dc6178f28a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b829635ab3c4fe79df44b4db695f08e"
          }
        },
        "86b2d8f760e64156975bdb557ea88119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cbe9ed8f3e054751bb685633a3ead951",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_160466234b5a432081ea0702c5cf7d02"
          }
        },
        "1ba91d9b442a43fd88d34eec60cdbe77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06f7720c351f40a5af5e4a63dc66489b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:01&lt;00:00,  1.01s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c34cb81ffd15417699a28baae4dafb14"
          }
        },
        "87602462cac54b128fb01dc6178f28a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b829635ab3c4fe79df44b4db695f08e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbe9ed8f3e054751bb685633a3ead951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "160466234b5a432081ea0702c5cf7d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06f7720c351f40a5af5e4a63dc66489b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c34cb81ffd15417699a28baae4dafb14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15a1376c38f84db3a614bf3e5196b24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_373921d994464f8e99ea2fee77fa3648",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_55f6c6eca66143f1a7391dd3032bcae4",
              "IPY_MODEL_2d0d8dc586b64f52ba4a3d72c752e761",
              "IPY_MODEL_52da44dd66e14f8e847eb0eeb54875cf"
            ]
          }
        },
        "373921d994464f8e99ea2fee77fa3648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "55f6c6eca66143f1a7391dd3032bcae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b7ab3060645a4e1f95dff50bb1f49e3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 0: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5a749f0fe6a4cc2ba7d9a1bb36fd2ed"
          }
        },
        "2d0d8dc586b64f52ba4a3d72c752e761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_654cde752cb8473fb8daf8fcc900af42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38f17aa98515441689c3f44dbe75900e"
          }
        },
        "52da44dd66e14f8e847eb0eeb54875cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f876d78b9f464042a26ddd4ebf55a5eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:25&lt;00:00,  8.54s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3ec74e4c0e749bc8f6a511ea2938a81"
          }
        },
        "b7ab3060645a4e1f95dff50bb1f49e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5a749f0fe6a4cc2ba7d9a1bb36fd2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "654cde752cb8473fb8daf8fcc900af42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38f17aa98515441689c3f44dbe75900e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f876d78b9f464042a26ddd4ebf55a5eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3ec74e4c0e749bc8f6a511ea2938a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ccf89252bd04d619a34e9b220fc91ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fbcb53d7b1fb4e54b8c3a88848c75a38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_667e6856cdc6405ca6d2f3dd9e089c6e",
              "IPY_MODEL_5fe2d241df1e48839d777e93f8433abd",
              "IPY_MODEL_1faaf71847d643b088f2ec9aca6c92c5"
            ]
          }
        },
        "fbcb53d7b1fb4e54b8c3a88848c75a38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "667e6856cdc6405ca6d2f3dd9e089c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_501b5e0e0aac4484900a355994e97618",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d32292119dc4cb9992489d64821f5ee"
          }
        },
        "5fe2d241df1e48839d777e93f8433abd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5f6c074dbd7d46a1b74c420479dff058",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_812cc7db899a4a72952e4fd5e06dc4cf"
          }
        },
        "1faaf71847d643b088f2ec9aca6c92c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48a5f36fa33c4abab90b1dd0f3385206",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:11&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f35809ebe444025b6394c664bca830f"
          }
        },
        "501b5e0e0aac4484900a355994e97618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d32292119dc4cb9992489d64821f5ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f6c074dbd7d46a1b74c420479dff058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "812cc7db899a4a72952e4fd5e06dc4cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48a5f36fa33c4abab90b1dd0f3385206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f35809ebe444025b6394c664bca830f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f9800b11c9a49c381bf58ef1a66e051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d2a35e2cdb8430d82b884bbf58c4a3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90aaf20062c0481f9bed6c04ee9961d2",
              "IPY_MODEL_c7280bdf80bc4b9ca8fc0bca061d6fef",
              "IPY_MODEL_b3e099380bd94a49afee0a6ab116dc28"
            ]
          }
        },
        "9d2a35e2cdb8430d82b884bbf58c4a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "90aaf20062c0481f9bed6c04ee9961d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff66447f0115417a977f0cfbb0cb2751",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1307f9ae90954189aa70c9bbe7767e24"
          }
        },
        "c7280bdf80bc4b9ca8fc0bca061d6fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a00e8b9c88f438abf76bdcf2cb5dba3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ece5ba493d0541069d75ec5e6bad6773"
          }
        },
        "b3e099380bd94a49afee0a6ab116dc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f62c000782a4fbf8111f5d175507fba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  4.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f97a39f08780450581d1e2ba4dde3ffb"
          }
        },
        "ff66447f0115417a977f0cfbb0cb2751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1307f9ae90954189aa70c9bbe7767e24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a00e8b9c88f438abf76bdcf2cb5dba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ece5ba493d0541069d75ec5e6bad6773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f62c000782a4fbf8111f5d175507fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f97a39f08780450581d1e2ba4dde3ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca0b14a9c92d4ffab917bb2798b37b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_009bc59922cb46d1a330e1851e9271e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_59b806174e8f43b7a7ac29394f18bb3c",
              "IPY_MODEL_161200feaee648a7891d1ac5c7bf1978",
              "IPY_MODEL_7613ab2e28e74300b413b2431953fc83"
            ]
          }
        },
        "009bc59922cb46d1a330e1851e9271e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "59b806174e8f43b7a7ac29394f18bb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e86d527216e8438cb982f9782f2ec253",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Testing: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ee2163cc5d141b0b4df6b10e6c37d05"
          }
        },
        "161200feaee648a7891d1ac5c7bf1978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a27f21a4f1644689b260e15817effea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0355f852a284be49654a5448331bf54"
          }
        },
        "7613ab2e28e74300b413b2431953fc83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc76aa25e9064c59a770d9df8a0cb479",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7162fb9ff83744a2bb2daef0d39372fe"
          }
        },
        "e86d527216e8438cb982f9782f2ec253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ee2163cc5d141b0b4df6b10e6c37d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a27f21a4f1644689b260e15817effea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0355f852a284be49654a5448331bf54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc76aa25e9064c59a770d9df8a0cb479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7162fb9ff83744a2bb2daef0d39372fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Clearbloo/Feynman_GNN/blob/main/Feynman_GNN_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZspqC4GXb_h-"
      },
      "source": [
        "#**Install and import libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmUsOZpbqF1W",
        "outputId": "587903fd-b753-45bf-e786-c90a2b70ef4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Collecting ray\n",
            "  Downloading ray-1.11.0-cp37-cp37m-manylinux2014_x86_64.whl (52.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 52.7 MB 85 kB/s \n",
            "\u001b[?25hCollecting redis>=3.5.0\n",
            "  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.3)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.5)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (4.11.2)\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray) (21.3)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray) (1.13.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray) (3.0.7)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Installing collected packages: deprecated, redis, grpcio, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.44.0\n",
            "    Uninstalling grpcio-1.44.0:\n",
            "      Successfully uninstalled grpcio-1.44.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n",
            "Successfully installed deprecated-1.2.13 grpcio-1.43.0 ray-1.11.0 redis-4.1.4\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/seed.py:53: UserWarning: No seed found, seed set to 1602145498\n",
            "  rank_zero_warn(f\"No seed found, seed set to {seed}\")\n",
            "Global seed set to 1602145498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 750 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 9.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import os.path as osp\n",
        "import json\n",
        "import math\n",
        "import numpy as np \n",
        "import time\n",
        "import pandas as pd\n",
        "import ast\n",
        "import random as rnd\n",
        "from typing import Optional\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
        "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from torch.nn import MSELoss\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "## Ray\n",
        "try:\n",
        "    import ray\n",
        "except ModuleNotFoundError: # Google Colab does not have Ray installed by default.\n",
        "    !pip install ray\n",
        "    import ray\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
        "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
        "\n",
        "## Tensorboard\n",
        "try:\n",
        "  import tensorboardX\n",
        "except ModuleNotFoundError:\n",
        "  !pip install tensorboardX\n",
        "  import tensorboardX\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"/content/gdrive/MyDrive/Part_III_Project/data/\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"/content/gdrive/MyDrive/Part_III_Project/saved_models/\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything()\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "# torch geometric\n",
        "try: \n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version. \n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details \n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install --quiet torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install --quiet torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install --quiet torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install --quiet torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install --quiet torch-geometric \n",
        "    import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data\n",
        "from torch_geometric.data import Dataset, Data, InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
        "from torch_geometric.nn import TopKPooling \n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGUB_wlSthxj"
      },
      "source": [
        "#**My own dataset class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Fl5qXWH9Hp7"
      },
      "outputs": [],
      "source": [
        "class FeynmanDataset(Dataset):\n",
        "    def __init__(self, dataset_size, filename, reprocess: bool = False, root=DATASET_PATH, test: bool = False, train: bool = False, val: bool = False, pred: bool = False, transform=None, pre_transform=None, pre_filter=None):\n",
        "      \"\"\"\n",
        "      root = directory where dataset should be stored. Contains raw data in raw_dir and processed data in processed_dir\n",
        "      test, train, val = bools, what type of dataset you want. default all false\n",
        "      \"\"\"\n",
        "      self.filename = filename\n",
        "      self.trunc_size= 10000\n",
        "      self.test = test \n",
        "      self.train = train\n",
        "      self.val = val\n",
        "      self.pred = pred\n",
        "      self.reproc = reprocess\n",
        "      self.label=\"full\"\n",
        "      if self.train == True:\n",
        "        self.label=\"train\"\n",
        "      if self.val == True:\n",
        "        self.label=\"val\"\n",
        "      if self.test == True:\n",
        "        self.label=\"test\"\n",
        "      if self.pred == True:\n",
        "        self.label=\"pred\"\n",
        "\n",
        "      if self.reproc == True:\n",
        "        overwrite_conf = input(\"This may overwrite old dataset files. Are you happy for this to happen? Type 'yes' to confirm. \\n\")\n",
        "        if overwrite_conf == 'yes':\n",
        "          pass\n",
        "      else:\n",
        "          self.reproc = False\n",
        "      \n",
        "      self.dataset_size = dataset_size\n",
        "      super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "      #skips download if this is found\n",
        "      return self.filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "      #will skip the process method if the following files are found\n",
        "      print(\"looking for files\")\n",
        "      if self.reproc == False:\n",
        "        proc_files = [0]*self.dataset_size\n",
        "        for idx in range(self.dataset_size):\n",
        "          proc_files[idx] =  f'{self.label}_data_{idx}.pt'\n",
        "        return proc_files\n",
        "      else:\n",
        "        return \"empty.pt\"\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`. In the future I will make this call a\n",
        "        # python file to build the dataset as a csv\n",
        "        print(\"No files to download\")\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "      print(\"processing starting\")\n",
        "      time.sleep(60)\n",
        "      print(\"reading data\")\n",
        "      self.full_data = pd.read_csv(self.raw_paths[0])\n",
        "      print(\"sampling data\")\n",
        "      self.data = self.full_data[0:self.dataset_size]\n",
        "      #self.data = self.full_data.sample(n=self.dataset_size)\n",
        "\n",
        "      #create a list of all y values\n",
        "      print(\"creating list of y values\")\n",
        "      all_y_values=self.data['y'].tolist()\n",
        "      y_max = max(all_y_values)\n",
        "      y_min = min(all_y_values)\n",
        "      \n",
        "\n",
        "      #truncate dataframe into smaller dataframes\n",
        "      split_size = math.ceil(self.dataset_size/self.trunc_size)\n",
        "      self.trunc_data_list = np.array_split(self.data, split_size)\n",
        "      #cycle through graphs and create data objects for each\n",
        "      idx=0\n",
        "      for k in tqdm(range(len(self.trunc_data_list))):\n",
        "        self.trunc_data=self.trunc_data_list[k]\n",
        "        for row, feyndiag in tqdm(self.trunc_data.iterrows(),total=self.trunc_data.shape[0]):\n",
        "          #node features\n",
        "          #start = time.time()\n",
        "          x = self._get_node_features(feyndiag)\n",
        "          #end=time.time()\n",
        "          #print(\"time to get node features: \", end-start)\n",
        "          #edge features\n",
        "          #start = time.time()\n",
        "          edge_attr = self._get_edge_features(feyndiag)\n",
        "          #end=time.time()\n",
        "          #print(\"time to get edge features: \", end-start)\n",
        "          #adjacency list\n",
        "          #start = time.time()\n",
        "          edge_index = self._get_adj_list(feyndiag)\n",
        "          #end = time.time()\n",
        "          #print(\"time to get adj list: \", end-start)\n",
        "          #targets\n",
        "          y = self._get_targets(feyndiag)\n",
        "          #normalized targets to the interval [0,1]\n",
        "          y_norm = (y-y_min)/(y_max-y_min)\n",
        "          \n",
        "          #create data object\n",
        "          #print(\"creating data object\")\n",
        "          data = Data(x=x, edge_index = edge_index, edge_attr=edge_attr, y=y, y_norm=y_norm)\n",
        "          #save file\n",
        "          start=time.time()\n",
        "          torch.save(data, osp.join(self.processed_dir, f'{self.label}_data_{idx}.pt'))\n",
        "          end=time.time()\n",
        "\n",
        "          if idx % 10000 == 0:\n",
        "            print(\"save time is: \", end-start)\n",
        "          idx+=1      \n",
        "\n",
        "    def _get_node_features(self, diagram):\n",
        "      \"\"\"\n",
        "      This will return a list of the node feature vectors (which are 1D)\n",
        "      [Number of Nodes, 1]\n",
        "      \"\"\"\n",
        "      x = ast.literal_eval(diagram.loc['x'])\n",
        "      x = torch.tensor(x,dtype=torch.float).view(-1,1)\n",
        "      return x\n",
        "\n",
        "    def _get_edge_features(self, diagram):\n",
        "      \"\"\"\n",
        "      This will return a list of the edge feature vectors (which are 11D)\n",
        "      [Number of Edges, 11]\n",
        "      \"\"\"\n",
        "      attr = ast.literal_eval(diagram.loc['edge_attr'])\n",
        "      return torch.tensor(attr,dtype=torch.float).view(-1,11)\n",
        "      \n",
        "    def _get_adj_list(self, diagram):\n",
        "      \"\"\"\n",
        "      This will return a list of the adjacency vectors (which are 2D)\n",
        "      [2, Number of Edges]\n",
        "      \"\"\"\n",
        "      adj_list = ast.literal_eval(diagram.loc['edge_index'])\n",
        "      return torch.tensor(adj_list,dtype=torch.long).view(2,-1)\n",
        "\n",
        "    def _get_targets(self, diagram):\n",
        "      \"\"\"\n",
        "      This will return a list of the target vectors (which are 1D)\n",
        "      [Number of targets, 1]\n",
        "      \"\"\"\n",
        "      y = diagram.loc['y']\n",
        "      return torch.tensor(y,dtype=torch.float)\n",
        "\n",
        "    def len(self):\n",
        "      return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "      data = torch.load(osp.join(self.processed_dir, f'{self.label}_data_{idx}.pt'))\n",
        "      return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"\n",
        "  Dataset extending the pytorch utils dataset class. Need to pass my an object with my own dataset class FeynmanDataset to it.\n",
        "  \"\"\"\n",
        "  def __init__(self, dataset):\n",
        "    self.dataset = dataset\n",
        "  def __len__(self):\n",
        "    return self.dataset.len()\n",
        "  def __getitem__(self, idx):\n",
        "    return self.dataset[idx]\n"
      ],
      "metadata": {
        "id": "9k5n537Ch2-O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fabV4BZbQJuB"
      },
      "source": [
        "#**Load the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DZuqvlzVRbLT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "cc8756b0-fc5f-4698-af9e-56111c6bba35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looking for files\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/gdrive/MyDrive/Part_III_Project/data/processed/full_data_2.pt'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-33ff1cc57eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#drive.mount(\"/content/gdrive\", force_remount=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'QED_data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfull_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeynmanDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1800000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-14d50fd7b98e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_size, filename, reprocess, root, test, train, val, pred, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'process'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \"'{self.processed_dir}' first\")\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfiles_exist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36mfiles_exist\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# NOTE: We return `False` in case `files` is empty, leading to a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# re-processing of files on every instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# NOTE: We return `False` in case `files` is empty, leading to a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# re-processing of files on every instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "filename = 'QED_data.csv'\n",
        "full_dataset = FeynmanDataset(dataset_size=1800000, filename=filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading datasets...\")\n",
        "train_dataset = FeynmanDataset(1000000, reprocess=False, filename=filename, train=True)\n",
        "test_dataset = FeynmanDataset(100, reprocess=False, filename=filename, test=True)\n",
        "val_dataset = FeynmanDataset(50, reprocess=False, filename=filename, val=True)\n",
        "pred_dataset = FeynmanDataset(10, reprocess=False, filename=filename, pred=True)\n",
        "print(\"Finished all!\")"
      ],
      "metadata": {
        "id": "28VT-m9Fi7bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.arange(1800000)\n",
        "rnd.shuffle(a)\n",
        "a.tolist()"
      ],
      "metadata": {
        "id": "0HSsKrWCjQs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q21G6_Tjq-vW",
        "outputId": "0acfe901-781c-46a1-c843-30525d2f653e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1421008,  959689,  696138,  234761, 1558025,  556954,  224539,\n",
              "       1727901, 1030543, 1711408])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar3Co5aKQL3u"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, num_workers=2)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=64, num_workers=2)\n",
        "pred_loader = DataLoader(dataset=pred_dataset, batch_size=1) #keep this batch_size as one to get predictions to work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZotGXzouB-Dj"
      },
      "source": [
        "#**Some loss functions**\n",
        "Defining some loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zWEkVjjB5Yr"
      },
      "outputs": [],
      "source": [
        "class LogCoshLoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, y_t, y_prime_t):\n",
        "        ey_t = y_t - y_prime_t\n",
        "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXS1oepDgkfR"
      },
      "outputs": [],
      "source": [
        "class RMSLELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        \n",
        "    def forward(self, pred, actual):\n",
        "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYNUWQmkBq47"
      },
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "    \n",
        "    def forward(self, pred, actual):\n",
        "      return torch.sqrt(self.mse(pred, actual))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK86ybzgev1g"
      },
      "source": [
        "#**Training code and GNN model using Lightning Module**\n",
        "\n",
        "* Lightning training module\n",
        "* Uses Transformer convolution layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDgx_mD0XzKk"
      },
      "outputs": [],
      "source": [
        "class FeynModel(pl.LightningModule):\n",
        "    def __init__(self, c_in, c_out, layer_name, model_params, filename='QED_data.csv'):\n",
        "        \"\"\"\n",
        "        c_in = channels in (feature dimensions, e.g. RGB is 3)\n",
        "        c_out = channels out (target dimension, e.g. classification is 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.filename=filename\n",
        "        self.batch_size = model_params[\"model_batch_size\"]\n",
        "        embedding_size = model_params[\"model_embedding_size\"]\n",
        "        n_heads = model_params[\"model_attention_heads\"]\n",
        "        self.n_layers = model_params[\"model_layers\"]\n",
        "        dropout_rate = model_params[\"model_dropout_rate\"]\n",
        "        top_k_ratio =  model_params[\"model_top_k_ratio\"]\n",
        "        self.top_k_every_n = model_params[\"model_top_k_every_n\"]\n",
        "        dense_neurons = model_params[\"model_dense_neurons\"]\n",
        "        edge_dim = model_params[\"model_edge_dim\"]-3 #remove momenta from edge_attr\n",
        "        edge_num = 5 #need to update this\n",
        "                \n",
        "        gnn_layer = gnn_layer_by_name[layer_name]\n",
        "        self.lr = model_params[\"model_learning_rate\"]\n",
        "        self.weight_decay = model_params[\"model_weight_decay\"]\n",
        "        self.lin_dropout_prob = model_params[\"model_lin_dropout_prob\"]\n",
        "        self.save_hyperparameters()\n",
        "        self.loss_fn = MSELoss()\n",
        "\n",
        "        self.conv_layers = ModuleList([])\n",
        "        self.transf_layers = ModuleList([])\n",
        "        self.pooling_layers = ModuleList([])\n",
        "        self.bn_layers = ModuleList([])\n",
        "\n",
        "        # Transformation layer\n",
        "        self.conv1 = gnn_layer(in_channels=c_in,\n",
        "                               out_channels=embedding_size, \n",
        "                               heads=n_heads, \n",
        "                               dropout=dropout_rate,\n",
        "                               edge_dim=edge_dim\n",
        "                               ) \n",
        "\n",
        "        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
        "        self.bn1 = BatchNorm1d(embedding_size)\n",
        "\n",
        "        # Other layers\n",
        "        for i in range(self.n_layers):\n",
        "            self.conv_layers.append(gnn_layer(embedding_size, \n",
        "                                              embedding_size, \n",
        "                                              heads=n_heads, \n",
        "                                              dropout=dropout_rate,\n",
        "                                              edge_dim=edge_dim,\n",
        "                                              ))\n",
        "\n",
        "            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
        "            self.bn_layers.append(BatchNorm1d(embedding_size))\n",
        "            if i % self.top_k_every_n == 0:\n",
        "                self.pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n",
        "            \n",
        "\n",
        "        # Linear layers\n",
        "        self.linear0 = Linear(embedding_size*2+3*2*edge_num, embedding_size*2)\n",
        "        self.linear1 = Linear((embedding_size)*2, dense_neurons)\n",
        "        self.linear2 = Linear(dense_neurons, c_out)\n",
        "\n",
        "        \"\"\"\n",
        "        could use super node instead of topKPooling an linear layers\n",
        "        or more topK pooling rather than linear layers\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch_index):\n",
        "        # Remove momenta from edge features\n",
        "        p = edge_attr[:,8:11]\n",
        "        p = p.reshape(max(batch_index)+1,-1)\n",
        "        edge_attr = edge_attr[:,0:8]\n",
        "\n",
        "        # Initial transformation\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = F.leaky_relu(self.transf1(x))\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        # Holds the intermediate graph representations\n",
        "        global_representation = []\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            x = self.conv_layers[i](x, edge_index, edge_attr)\n",
        "            x = F.leaky_relu(self.transf_layers[i](x))\n",
        "            x = self.bn_layers[i](x)\n",
        "            # Always aggregate last layer\n",
        "            if i % self.top_k_every_n == 0 or i == self.n_layers:\n",
        "                x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](\n",
        "                    x, edge_index, edge_attr, batch_index\n",
        "                    )\n",
        "                # Add current representation\n",
        "                global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
        "    \n",
        "        x = sum(global_representation)\n",
        "\n",
        "        #add momenta on\n",
        "        x = torch.cat((x,p),1)\n",
        "\n",
        "        # Output block\n",
        "        x = F.leaky_relu(self.linear0(x))\n",
        "        x = F.dropout(x,p=self.lin_dropout_prob, training=self.training)\n",
        "        x = F.leaky_relu(self.linear1(x))\n",
        "        x = F.dropout(x, p=self.lin_dropout_prob, training=self.training)\n",
        "        x = torch.sigmoid(self.linear2(x))\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, edge_index, edge_attr, y = batch['x'], batch['edge_index'], batch['edge_attr'], batch['y_norm']\n",
        "        batch_idx = batch['batch']\n",
        "        y_hat = self(x,\n",
        "                     edge_index,\n",
        "                     edge_attr,\n",
        "                     batch_idx\n",
        "        )\n",
        "        loss = self.loss_fn(y_hat, y.view(-1,1))\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=False, batch_size=max(batch_idx)+1)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, edge_index, edge_attr, y = batch['x'], batch['edge_index'], batch['edge_attr'], batch['y_norm']\n",
        "        batch_idx = batch['batch']\n",
        "        y_hat = self(x,\n",
        "                     edge_index,\n",
        "                     edge_attr,\n",
        "                     batch_idx\n",
        "        )\n",
        "        loss = self.loss_fn(y_hat, y.view(-1,1))\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, batch_size=max(batch_idx)+1)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, edge_index, edge_attr, y = batch['x'], batch['edge_index'], batch['edge_attr'], batch['y_norm']\n",
        "        batch_idx = batch['batch']\n",
        "        y_hat = self(x,\n",
        "                     edge_index,\n",
        "                     edge_attr,\n",
        "                     batch_idx)\n",
        "        loss = self.loss_fn(y_hat, y.view(-1,1))\n",
        "        self.log(\"test_loss\", loss, prog_bar=True, on_step=True, on_epoch=False, batch_size=max(batch_idx)+1)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x, edge_index, edge_attr, y = batch['x'], batch['edge_index'], batch['edge_attr'], batch['y_norm']\n",
        "        batch_idx = batch['batch']\n",
        "        y_hat = self(x,\n",
        "                     edge_index,\n",
        "                     edge_attr,\n",
        "                     batch_idx)\n",
        "        return y_hat.item(), y.item()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(),\n",
        "                                lr=self.lr,\n",
        "                                weight_decay=self.weight_decay,\n",
        "                                )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Tuning the hyperparameters with Ray Tune**"
      ],
      "metadata": {
        "id": "dLopbX9b_spV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_feyn_no_tune(params, num_gpus, num_epochs=10):\n",
        "  \"\"\"\n",
        "  Function to train the Feynman GNN without a hyperparameter search.\n",
        "  params = The hyperparameters to use, stored as a dictionary with the notation \"model_...\"\n",
        "  \"\"\"\n",
        "  #need to make layer type a hyperparameter\n",
        "  model_params = {k: v[0] for k, v in params.items() if k.startswith(\"model_\")}\n",
        "  model = FeynModel(c_in=-1, #train_dataset.num_node_features \n",
        "                    c_out=1,  #train_dataset.num_classes\n",
        "                    layer_name=\"GAT\",\n",
        "                    model_params=model_params,\n",
        "                    #filename=\n",
        "                    )\n",
        "  trainer = pl.Trainer(logger=TensorBoardLogger(CHECKPOINT_PATH, name=\"tb_logs\"),\n",
        "                       max_epochs=num_epochs,\n",
        "                       gpus=math.ceil(num_gpus),\n",
        "                       log_every_n_steps=10,\n",
        "                       #progress_bar_refresh_rate=0,\n",
        "                       callbacks=[EarlyStopping('val_loss',patience=10)],\n",
        "                       )\n",
        "  trainer.fit(model, train_loader, val_loader)\n",
        "  trainer.validate(model, val_loader)\n",
        "  trainer.test(model, test_loader)\n",
        "  return model, trainer\n"
      ],
      "metadata": {
        "id": "PDfp1TeIASgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySMx4x_0X6rM"
      },
      "outputs": [],
      "source": [
        "def train_feyn_tune(config, num_epochs=10, num_gpus=0, checkpoint_dir=None):\n",
        "  \"\"\"\n",
        "  function to run a training run that will be called later by the tuning function\n",
        "  \"\"\"\n",
        "  model = FeynModel(c_in=-1, #train_dataset.num_node_features \n",
        "                    c_out=1,  #train_dataset.num_classes\n",
        "                    layer_name=\"GAT\",\n",
        "                    model_params=config,\n",
        "                    #filename=\n",
        "                    )\n",
        "  trainer = pl.Trainer(logger=TensorBoardLogger(save_dir=tune.get_trial_dir(),\n",
        "                                                name=\"\",\n",
        "                                                version=\".\"),\n",
        "                       max_epochs=num_epochs,\n",
        "                       gpus=math.ceil(num_gpus),\n",
        "                       log_every_n_steps=10,\n",
        "                       #progress_bar_refresh_rate=0,\n",
        "                       callbacks=[TuneReportCallback({\"loss\": \"val_loss\",   \n",
        "                                                      #\"mean_accuracy\": \"val_acc\"\n",
        "                                                      },\n",
        "                                                     on=\"validation_end\"),\n",
        "                                  #EarlyStopping('val_loss',patience=10)\n",
        "                                  ]\n",
        "                       )\n",
        "  trainer.fit(model, train_loader, val_loader)\n",
        "\n",
        "\n",
        "def tune_feyn_asha(config, gpus_per_trial=0, num_epochs=10, num_samples=10):\n",
        "\n",
        "    scheduler = ASHAScheduler(\n",
        "        max_t=num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "    reporter = CLIReporter(\n",
        "        parameter_columns=[\n",
        "                           \"model_batch_size\",\n",
        "                           \"model_weight_decay\",\n",
        "                           \"model_learning_rate\",\n",
        "                           \"model_embedding_size\",\n",
        "                           \"model_attention_heads\",\n",
        "                           \"model_layers\",\n",
        "                           \"model_dropout_rate\",\n",
        "                           \"model_top_k_ratio\",\n",
        "                           \"model_top_k_every_n\",\n",
        "                           \"model_dense_neurons\",\n",
        "                           \"model_edge_dim\",\n",
        "                           \"model_lin_dropout_prob\"],\n",
        "        metric_columns=[\"loss\", \"training_iteration\"])\n",
        "\n",
        "    train_fn_with_parameters = tune.with_parameters(train_feyn_tune,\n",
        "                                                    num_epochs=num_epochs,\n",
        "                                                    num_gpus=gpus_per_trial,\n",
        "                                                    #checkpoint_dir=CHECKPOINT_PATH,\n",
        "                                                    )\n",
        "    \n",
        "    resources_per_trial = {\"cpu\": 1, \"gpu\": gpus_per_trial}\n",
        "\n",
        "    analysis = tune.run(train_fn_with_parameters,\n",
        "        resources_per_trial=resources_per_trial,\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        name=\"tune_mnist_asha\")\n",
        "\n",
        "    print(\"Best hyperparameters found were: \", analysis.best_config)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  gpus=1\n",
        "else:\n",
        "  gpus=0"
      ],
      "metadata": {
        "id": "hQFzsPHBBJzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169a9407-94bb-4de3-ad5d-c2f126fcb29a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 1.10.0+cu111\n",
            "Cuda available: False\n",
            "Torch geometric version: 2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oZGz9gpDFdT"
      },
      "source": [
        "#**Create layer dictionary and Hyperparameters**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aw_Cv-GPPRxY"
      },
      "outputs": [],
      "source": [
        "#layer name dictionary\n",
        "gnn_layer_by_name = {\n",
        "    \"GCN\": geom_nn.GCNConv,\n",
        "    \"GAT\": geom_nn.GATConv,\n",
        "    \"GraphConv\": geom_nn.GraphConv,\n",
        "    \"NNConv\": geom_nn.NNConv,\n",
        "    \"RGCN\": geom_nn.RGCNConv,\n",
        "    \"Trans\": geom_nn.TransformerConv\n",
        "}\n",
        "\n",
        "#Hyperparameters to use if not tuning\n",
        "HYPERPARAMETERS = {\n",
        "    \"model_batch_size\": [80],\n",
        "    \"model_weight_decay\": [0.000001],\n",
        "    \"model_learning_rate\": [0.0001],\n",
        "    \"model_embedding_size\": [16],\n",
        "    \"model_attention_heads\": [4],\n",
        "    \"model_layers\": [5],\n",
        "    \"model_dropout_rate\": [0.6],\n",
        "    \"model_top_k_ratio\": [0.5],\n",
        "    \"model_top_k_every_n\": [1],\n",
        "    \"model_dense_neurons\": [4],\n",
        "    \"model_edge_dim\": [11],\n",
        "    \"model_lin_dropout_prob\": [0.8],\n",
        "    }\n",
        "\n",
        "#Hyperparameters for ray tune to search through\n",
        "config = {\n",
        "    \"model_batch_size\": tune.choice([64]),\n",
        "    \"model_weight_decay\": tune.choice([0.000001]),\n",
        "    \"model_learning_rate\": tune.loguniform(0.0001,0.1),\n",
        "    \"model_embedding_size\": tune.choice([4]),\n",
        "    \"model_attention_heads\": tune.choice([4]),\n",
        "    \"model_layers\": tune.choice([3]),\n",
        "    \"model_dropout_rate\": tune.choice([0.5]),\n",
        "    \"model_top_k_ratio\": tune.choice([0.2]),\n",
        "    \"model_top_k_every_n\": tune.choice([1]),\n",
        "    \"model_dense_neurons\": tune.choice([4]),\n",
        "    \"model_edge_dim\": tune.choice([11]),\n",
        "    \"model_lin_dropout_prob\": tune.choice([0.3]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, trainer = train_feyn_no_tune(HYPERPARAMETERS,gpus,200)"
      ],
      "metadata": {
        "id": "1OF1U2nVMDbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738,
          "referenced_widgets": [
            "71a7962e314f4e0db544fc607af67168",
            "6bf4439f0b3a47a79544ab47cf0450ee",
            "49f8212a977b493896c0ffb037b34277",
            "86b2d8f760e64156975bdb557ea88119",
            "1ba91d9b442a43fd88d34eec60cdbe77",
            "87602462cac54b128fb01dc6178f28a3",
            "8b829635ab3c4fe79df44b4db695f08e",
            "cbe9ed8f3e054751bb685633a3ead951",
            "160466234b5a432081ea0702c5cf7d02",
            "06f7720c351f40a5af5e4a63dc66489b",
            "c34cb81ffd15417699a28baae4dafb14",
            "15a1376c38f84db3a614bf3e5196b24a",
            "373921d994464f8e99ea2fee77fa3648",
            "55f6c6eca66143f1a7391dd3032bcae4",
            "2d0d8dc586b64f52ba4a3d72c752e761",
            "52da44dd66e14f8e847eb0eeb54875cf",
            "b7ab3060645a4e1f95dff50bb1f49e3a",
            "d5a749f0fe6a4cc2ba7d9a1bb36fd2ed",
            "654cde752cb8473fb8daf8fcc900af42",
            "38f17aa98515441689c3f44dbe75900e",
            "f876d78b9f464042a26ddd4ebf55a5eb",
            "f3ec74e4c0e749bc8f6a511ea2938a81",
            "9ccf89252bd04d619a34e9b220fc91ab",
            "fbcb53d7b1fb4e54b8c3a88848c75a38",
            "667e6856cdc6405ca6d2f3dd9e089c6e",
            "5fe2d241df1e48839d777e93f8433abd",
            "1faaf71847d643b088f2ec9aca6c92c5",
            "501b5e0e0aac4484900a355994e97618",
            "1d32292119dc4cb9992489d64821f5ee",
            "5f6c074dbd7d46a1b74c420479dff058",
            "812cc7db899a4a72952e4fd5e06dc4cf",
            "48a5f36fa33c4abab90b1dd0f3385206",
            "7f35809ebe444025b6394c664bca830f",
            "2f9800b11c9a49c381bf58ef1a66e051",
            "9d2a35e2cdb8430d82b884bbf58c4a3b",
            "90aaf20062c0481f9bed6c04ee9961d2",
            "c7280bdf80bc4b9ca8fc0bca061d6fef",
            "b3e099380bd94a49afee0a6ab116dc28",
            "ff66447f0115417a977f0cfbb0cb2751",
            "1307f9ae90954189aa70c9bbe7767e24",
            "7a00e8b9c88f438abf76bdcf2cb5dba3",
            "ece5ba493d0541069d75ec5e6bad6773",
            "3f62c000782a4fbf8111f5d175507fba",
            "f97a39f08780450581d1e2ba4dde3ffb",
            "ca0b14a9c92d4ffab917bb2798b37b5c",
            "009bc59922cb46d1a330e1851e9271e4",
            "59b806174e8f43b7a7ac29394f18bb3c",
            "161200feaee648a7891d1ac5c7bf1978",
            "7613ab2e28e74300b413b2431953fc83",
            "e86d527216e8438cb982f9782f2ec253",
            "2ee2163cc5d141b0b4df6b10e6c37d05",
            "7a27f21a4f1644689b260e15817effea",
            "b0355f852a284be49654a5448331bf54",
            "fc76aa25e9064c59a770d9df8a0cb479",
            "7162fb9ff83744a2bb2daef0d39372fe"
          ]
        },
        "outputId": "6204edfb-9f92-46d9-87d8-a0035366230c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "  \"A layer with UninitializedParameter was found. \"\n",
            "\n",
            "   | Name           | Type        | Params\n",
            "------------------------------------------------\n",
            "0  | loss_fn        | MSELoss     | 0     \n",
            "1  | conv_layers    | ModuleList  | 9.0 K \n",
            "2  | transf_layers  | ModuleList  | 5.2 K \n",
            "3  | pooling_layers | ModuleList  | 80    \n",
            "4  | bn_layers      | ModuleList  | 160   \n",
            "5  | conv1          | GATConv     | 768   \n",
            "6  | transf1        | Linear      | 1.0 K \n",
            "7  | bn1            | BatchNorm1d | 32    \n",
            "8  | linear0        | Linear      | 2.0 K \n",
            "9  | linear1        | Linear      | 132   \n",
            "10 | linear2        | Linear      | 5     \n",
            "------------------------------------------------\n",
            "18.4 K    Trainable params\n",
            "0         Non-trainable params\n",
            "18.4 K    Total params\n",
            "0.074     Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71a7962e314f4e0db544fc607af67168",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 3125819298\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15a1376c38f84db3a614bf3e5196b24a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ccf89252bd04d619a34e9b220fc91ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f9800b11c9a49c381bf58ef1a66e051",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 VALIDATE RESULTS\n",
            "{'val_loss': 0.4919202923774719}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca0b14a9c92d4ffab917bb2798b37b5c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear0.weight"
      ],
      "metadata": {
        "id": "FJI1MsXRXhIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tune_feyn_asha(config, gpus_per_trial=gpus)"
      ],
      "metadata": {
        "id": "LlxllxPBQKuS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d5445cd-0226-46e6-cb0c-41e59ef10814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:13 (running for 00:00:00.29)\n",
            "Memory usage on this node: 2.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 | RUNNING  | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | PENDING  |                 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00002 | PENDING  |                 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | PENDING  |                 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00004 | PENDING  |                 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | PENDING  |                 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00006 | PENDING  |                 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | PENDING  |                 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m    | Name           | Type        | Params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 0  | loss_fn        | MSELoss     | 0     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 1  | conv_layers    | ModuleList  | 768   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 2  | transf_layers  | ModuleList  | 204   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 3  | pooling_layers | ModuleList  | 12    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 4  | bn_layers      | ModuleList  | 24    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 5  | conv1          | GATConv     | 192   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 6  | transf1        | Linear      | 68    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 7  | bn1            | BatchNorm1d | 8     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 8  | linear0        | Linear      | 312   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 9  | linear1        | Linear      | 36    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 10 | linear2        | Linear      | 5     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 1.6 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 1.6 K     Total params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 0.007     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m 2022-03-10 16:04:21,891\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m Exception in thread Thread-6:\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 281, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m \n",
            "2022-03-10 16:04:22,016\tERROR trial_runner.py:920 -- Trial train_feyn_tune_ba3ed_00000: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 886, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 675, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1763, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1155, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 319, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 381, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1155, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "    self.training_type_plugin.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "    self._run_sanity_check(self.lightning_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "    self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "    self.on_run_start(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "    dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "    self.prefetching(self.prefetch_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "    self._fetch_next_batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "    batch = next(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "TypeError: 'FeynmanDataset' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:18 (running for 00:00:05.34)\n",
            "Memory usage on this node: 2.5/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 | RUNNING  | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | RUNNING  | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00002 | PENDING  |                 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | PENDING  |                 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00004 | PENDING  |                 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | PENDING  |                 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00006 | PENDING  |                 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | PENDING  |                 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1155)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Result for train_feyn_tune_ba3ed_00000:\n",
            "  date: 2022-03-10_16-04-17\n",
            "  experiment_id: 93a75de1f25f4466809dd75979f180dd\n",
            "  hostname: 5fbc48a868f9\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1155\n",
            "  timestamp: 1646928257\n",
            "  trial_id: ba3ed_00000\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:23 (running for 00:00:11.26)\n",
            "Memory usage on this node: 3.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (1 ERROR, 8 PENDING, 1 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00001 | RUNNING  | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00002 | PENDING  |                 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | PENDING  |                 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00004 | PENDING  |                 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | PENDING  |                 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00006 | PENDING  |                 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | PENDING  |                 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00000 | ERROR    | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "Number of errored trials: 1\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  |   # failures | error file                                                                                                                                                                                         |\n",
            "|-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00000_0_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-12/error.txt |\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m    | Name           | Type        | Params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 0  | loss_fn        | MSELoss     | 0     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 1  | conv_layers    | ModuleList  | 768   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 2  | transf_layers  | ModuleList  | 204   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 3  | pooling_layers | ModuleList  | 12    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 4  | bn_layers      | ModuleList  | 24    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 5  | conv1          | GATConv     | 192   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 6  | transf1        | Linear      | 68    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 7  | bn1            | BatchNorm1d | 8     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 8  | linear0        | Linear      | 312   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 9  | linear1        | Linear      | 36    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 10 | linear2        | Linear      | 5     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 1.6 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 1.6 K     Total params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 0.007     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m 2022-03-10 16:04:24,584\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m Exception in thread Thread-6:\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 281, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1154)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-10 16:04:24,798\tERROR trial_runner.py:920 -- Trial train_feyn_tune_ba3ed_00001: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 886, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 675, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1763, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1154, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 319, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 381, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1154, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "    self.training_type_plugin.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "    self._run_sanity_check(self.lightning_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "    self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "    self.on_run_start(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "    dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "    self.prefetching(self.prefetch_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "    self._fetch_next_batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "    batch = next(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "TypeError: 'FeynmanDataset' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_feyn_tune_ba3ed_00001:\n",
            "  date: 2022-03-10_16-04-21\n",
            "  experiment_id: a855dffaa3dc446b9f2b087ef945401d\n",
            "  hostname: 5fbc48a868f9\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1154\n",
            "  timestamp: 1646928261\n",
            "  trial_id: ba3ed_00001\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:29 (running for 00:00:16.78)\n",
            "Memory usage on this node: 3.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (2 ERROR, 7 PENDING, 1 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00002 | RUNNING  | 172.28.0.2:1276 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | PENDING  |                 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00004 | PENDING  |                 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | PENDING  |                 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00006 | PENDING  |                 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | PENDING  |                 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00000 | ERROR    | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | ERROR    | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "Number of errored trials: 2\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  |   # failures | error file                                                                                                                                                                                         |\n",
            "|-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00000_0_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-12/error.txt |\n",
            "| train_feyn_tune_ba3ed_00001 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00001_1_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m    | Name           | Type        | Params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 0  | loss_fn        | MSELoss     | 0     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 1  | conv_layers    | ModuleList  | 768   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 2  | transf_layers  | ModuleList  | 204   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 3  | pooling_layers | ModuleList  | 12    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 4  | bn_layers      | ModuleList  | 24    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 5  | conv1          | GATConv     | 192   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 6  | transf1        | Linear      | 68    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 7  | bn1            | BatchNorm1d | 8     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 8  | linear0        | Linear      | 312   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 9  | linear1        | Linear      | 36    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 10 | linear2        | Linear      | 5     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 1.6 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 1.6 K     Total params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 0.007     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m 2022-03-10 16:04:34,502\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m Exception in thread Thread-3:\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 281, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m \n",
            "2022-03-10 16:04:34,599\tERROR trial_runner.py:920 -- Trial train_feyn_tune_ba3ed_00002: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 886, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 675, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1763, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1276, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 319, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 381, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1276, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "    self.training_type_plugin.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "    self._run_sanity_check(self.lightning_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "    self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "    self.on_run_start(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "    dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "    self.prefetching(self.prefetch_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "    self._fetch_next_batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "    batch = next(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "TypeError: 'FeynmanDataset' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1276)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:34 (running for 00:00:21.81)\n",
            "Memory usage on this node: 3.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (2 ERROR, 6 PENDING, 2 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00002 | RUNNING  | 172.28.0.2:1276 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | RUNNING  | 172.28.0.2:1304 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00004 | PENDING  |                 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | PENDING  |                 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00006 | PENDING  |                 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | PENDING  |                 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00000 | ERROR    | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | ERROR    | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "Number of errored trials: 2\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  |   # failures | error file                                                                                                                                                                                         |\n",
            "|-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00000_0_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-12/error.txt |\n",
            "| train_feyn_tune_ba3ed_00001 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00001_1_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Result for train_feyn_tune_ba3ed_00002:\n",
            "  date: 2022-03-10_16-04-30\n",
            "  experiment_id: 8311790212204bd5b4a6b2b19875a172\n",
            "  hostname: 5fbc48a868f9\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1276\n",
            "  timestamp: 1646928270\n",
            "  trial_id: ba3ed_00002\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m    | Name           | Type        | Params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 0  | loss_fn        | MSELoss     | 0     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 1  | conv_layers    | ModuleList  | 768   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 2  | transf_layers  | ModuleList  | 204   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 3  | pooling_layers | ModuleList  | 12    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 4  | bn_layers      | ModuleList  | 24    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 5  | conv1          | GATConv     | 192   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 6  | transf1        | Linear      | 68    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 7  | bn1            | BatchNorm1d | 8     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 8  | linear0        | Linear      | 312   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 9  | linear1        | Linear      | 36    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 10 | linear2        | Linear      | 5     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 1.6 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 1.6 K     Total params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 0.007     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m 2022-03-10 16:04:37,759\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m Exception in thread Thread-3:\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 281, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m \n",
            "2022-03-10 16:04:37,956\tERROR trial_runner.py:920 -- Trial train_feyn_tune_ba3ed_00003: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 886, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 675, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1763, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1304, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 319, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 381, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1304, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "    self.training_type_plugin.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "    self._run_sanity_check(self.lightning_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "    self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "    self.on_run_start(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "    dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "    self.prefetching(self.prefetch_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "    self._fetch_next_batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "    batch = next(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "TypeError: 'FeynmanDataset' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1304)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Result for train_feyn_tune_ba3ed_00003:\n",
            "  date: 2022-03-10_16-04-34\n",
            "  experiment_id: dda33b23f3a945d284a3b214dde0ceba\n",
            "  hostname: 5fbc48a868f9\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1304\n",
            "  timestamp: 1646928274\n",
            "  trial_id: ba3ed_00003\n",
            "  \n",
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:40 (running for 00:00:27.28)\n",
            "Memory usage on this node: 2.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (4 ERROR, 5 PENDING, 1 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00004 | RUNNING  | 172.28.0.2:1354 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | PENDING  |                 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00006 | PENDING  |                 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | PENDING  |                 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00000 | ERROR    | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | ERROR    | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00002 | ERROR    | 172.28.0.2:1276 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | ERROR    | 172.28.0.2:1304 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "Number of errored trials: 4\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  |   # failures | error file                                                                                                                                                                                         |\n",
            "|-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00000_0_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-12/error.txt |\n",
            "| train_feyn_tune_ba3ed_00001 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00001_1_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00002 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00002_2_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00003 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00003_3_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-27/error.txt |\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:45 (running for 00:00:32.35)\n",
            "Memory usage on this node: 2.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (4 ERROR, 4 PENDING, 2 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00004 | RUNNING  | 172.28.0.2:1354 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | RUNNING  | 172.28.0.2:1398 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00006 | PENDING  |                 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | PENDING  |                 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00000 | ERROR    | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | ERROR    | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00002 | ERROR    | 172.28.0.2:1276 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | ERROR    | 172.28.0.2:1304 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "Number of errored trials: 4\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  |   # failures | error file                                                                                                                                                                                         |\n",
            "|-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00000_0_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-12/error.txt |\n",
            "| train_feyn_tune_ba3ed_00001 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00001_1_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00002 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00002_2_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00003 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00003_3_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-27/error.txt |\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m    | Name           | Type        | Params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 0  | loss_fn        | MSELoss     | 0     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 1  | conv_layers    | ModuleList  | 768   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 2  | transf_layers  | ModuleList  | 204   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 3  | pooling_layers | ModuleList  | 12    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 4  | bn_layers      | ModuleList  | 24    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 5  | conv1          | GATConv     | 192   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 6  | transf1        | Linear      | 68    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 7  | bn1            | BatchNorm1d | 8     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 8  | linear0        | Linear      | 312   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 9  | linear1        | Linear      | 36    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 10 | linear2        | Linear      | 5     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 1.6 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 1.6 K     Total params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 0.007     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m 2022-03-10 16:04:45,938\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m Exception in thread Thread-3:\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 281, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1354)\u001b[0m \n",
            "2022-03-10 16:04:46,060\tERROR trial_runner.py:920 -- Trial train_feyn_tune_ba3ed_00004: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 886, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 675, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1763, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1354, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 319, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 381, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1354, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "    self.training_type_plugin.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "    self._run_sanity_check(self.lightning_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "    self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "    self.on_run_start(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "    dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "    self.prefetching(self.prefetch_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "    self._fetch_next_batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "    batch = next(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "TypeError: 'FeynmanDataset' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_feyn_tune_ba3ed_00004:\n",
            "  date: 2022-03-10_16-04-41\n",
            "  experiment_id: 9ad1488b08224b0bb61ba208b1667917\n",
            "  hostname: 5fbc48a868f9\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1354\n",
            "  timestamp: 1646928281\n",
            "  trial_id: ba3ed_00004\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-10 16:04:48,517\tERROR trial_runner.py:920 -- Trial train_feyn_tune_ba3ed_00005: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 886, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 675, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1763, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1398, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 319, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 381, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1398, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "    self.training_type_plugin.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "    self._run_sanity_check(self.lightning_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "    self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "    self.on_run_start(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "    dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "    self.prefetching(self.prefetch_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "    self._fetch_next_batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "    batch = next(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m    | Name           | Type        | Params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 0  | loss_fn        | MSELoss     | 0     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 1  | conv_layers    | ModuleList  | 768   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 2  | transf_layers  | ModuleList  | 204   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 3  | pooling_layers | ModuleList  | 12    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 4  | bn_layers      | ModuleList  | 24    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 5  | conv1          | GATConv     | 192   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 6  | transf1        | Linear      | 68    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 7  | bn1            | BatchNorm1d | 8     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 8  | linear0        | Linear      | 312   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 9  | linear1        | Linear      | 36    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 10 | linear2        | Linear      | 5     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 1.6 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 1.6 K     Total params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 0.007     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m 2022-03-10 16:04:48,479\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m Exception in thread Thread-3:\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 281, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_feyn_tune_ba3ed_00005:\n",
            "  date: 2022-03-10_16-04-45\n",
            "  experiment_id: 5644c6ad3124404da9b81c6bdad21837\n",
            "  hostname: 5fbc48a868f9\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1398\n",
            "  timestamp: 1646928285\n",
            "  trial_id: ba3ed_00005\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1398)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:50 (running for 00:00:38.24)\n",
            "Memory usage on this node: 3.3/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 1.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (6 ERROR, 3 PENDING, 1 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00006 | RUNNING  | 172.28.0.2:1460 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | PENDING  |                 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00000 | ERROR    | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | ERROR    | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00002 | ERROR    | 172.28.0.2:1276 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | ERROR    | 172.28.0.2:1304 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00004 | ERROR    | 172.28.0.2:1354 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | ERROR    | 172.28.0.2:1398 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "Number of errored trials: 6\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  |   # failures | error file                                                                                                                                                                                         |\n",
            "|-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00000_0_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-12/error.txt |\n",
            "| train_feyn_tune_ba3ed_00001 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00001_1_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00002 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00002_2_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00003 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00003_3_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-27/error.txt |\n",
            "| train_feyn_tune_ba3ed_00004 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00004_4_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-30/error.txt |\n",
            "| train_feyn_tune_ba3ed_00005 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00005_5_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-39/error.txt |\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m    | Name           | Type        | Params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 0  | loss_fn        | MSELoss     | 0     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 1  | conv_layers    | ModuleList  | 768   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 2  | transf_layers  | ModuleList  | 204   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 3  | pooling_layers | ModuleList  | 12    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 4  | bn_layers      | ModuleList  | 24    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 5  | conv1          | GATConv     | 192   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 6  | transf1        | Linear      | 68    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 7  | bn1            | BatchNorm1d | 8     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 8  | linear0        | Linear      | 312   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 9  | linear1        | Linear      | 36    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 10 | linear2        | Linear      | 5     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 1.6 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 1.6 K     Total params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 0.007     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m 2022-03-10 16:04:56,971\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m Exception in thread Thread-3:\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 281, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m GPU available: False, used: False\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m IPU available: False, using: 0 IPUs\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/configuration_validator.py:276: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   \"The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7.\"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m \n",
            "2022-03-10 16:04:57,095\tERROR trial_runner.py:920 -- Trial train_feyn_tune_ba3ed_00006: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 886, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 675, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1763, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1460, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 319, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 381, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1460, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "    self.training_type_plugin.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "    self._run_sanity_check(self.lightning_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "    self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "    self.on_run_start(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "    dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "    self.prefetching(self.prefetch_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "    self._fetch_next_batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "    batch = next(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "TypeError: 'FeynmanDataset' object is not subscriptable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1460)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "== Status ==\n",
            "Current time: 2022-03-10 16:04:56 (running for 00:00:43.29)\n",
            "Memory usage on this node: 2.9/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (6 ERROR, 2 PENDING, 2 RUNNING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00006 | RUNNING  | 172.28.0.2:1460 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | RUNNING  | 172.28.0.2:1493 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00000 | ERROR    | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | ERROR    | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00002 | ERROR    | 172.28.0.2:1276 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | ERROR    | 172.28.0.2:1304 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00004 | ERROR    | 172.28.0.2:1354 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | ERROR    | 172.28.0.2:1398 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "Number of errored trials: 6\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  |   # failures | error file                                                                                                                                                                                         |\n",
            "|-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00000_0_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-12/error.txt |\n",
            "| train_feyn_tune_ba3ed_00001 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00001_1_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00002 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00002_2_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00003 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00003_3_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-27/error.txt |\n",
            "| train_feyn_tune_ba3ed_00004 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00004_4_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-30/error.txt |\n",
            "| train_feyn_tune_ba3ed_00005 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00005_5_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-39/error.txt |\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Result for train_feyn_tune_ba3ed_00006:\n",
            "  date: 2022-03-10_16-04-52\n",
            "  experiment_id: bd8838b89d9748dd98e34f1facf3c1d6\n",
            "  hostname: 5fbc48a868f9\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1460\n",
            "  timestamp: 1646928292\n",
            "  trial_id: ba3ed_00006\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-10 16:04:59,579\tERROR trial_runner.py:920 -- Trial train_feyn_tune_ba3ed_00007: Error processing event.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\", line 886, in _process_trial\n",
            "    results = self.trial_executor.fetch_result(trial)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\", line 675, in fetch_result\n",
            "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 1763, in get\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1493, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 319, in train\n",
            "    result = self.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 381, in step\n",
            "    self._report_thread_runner_error(block=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 532, in _report_thread_runner_error\n",
            "    (\"Trial raised an exception. Traceback:\\n{}\".format(err_tb_str)\n",
            "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
            "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1493, ip=172.28.0.2, repr=train_feyn_tune)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "    self._entrypoint()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "    self._status_reporter.get_checkpoint())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "    trainable(config, **fn_kwargs)\n",
            "  File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "    self._dispatch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "    self.training_type_plugin.start_training(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "    self._results = trainer.run_stage()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "    return self._run_train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "    self._run_sanity_check(self.lightning_module)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "    self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "    self.advance(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "    self.on_run_start(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "    self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "    dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "    self.prefetching(self.prefetch_batches)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "    self._fetch_next_batch()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "    batch = next(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m /usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/model_summary.py:439: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   \"A layer with UninitializedParameter was found. \"\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m    | Name           | Type        | Params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 0  | loss_fn        | MSELoss     | 0     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 1  | conv_layers    | ModuleList  | 768   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 2  | transf_layers  | ModuleList  | 204   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 3  | pooling_layers | ModuleList  | 12    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 4  | bn_layers      | ModuleList  | 24    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 5  | conv1          | GATConv     | 192   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 6  | transf1        | Linear      | 68    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 7  | bn1            | BatchNorm1d | 8     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 8  | linear0        | Linear      | 312   \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 9  | linear1        | Linear      | 36    \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 10 | linear2        | Linear      | 5     \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m ------------------------------------------------\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 1.6 K     Trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 0         Non-trainable params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 1.6 K     Total params\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 0.007     Total estimated model params size (MB)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m 2022-03-10 16:04:59,544\tERROR function_runner.py:268 -- Runner Thread raised error.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m Exception in thread Thread-3:\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 281, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     raise e\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 262, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._entrypoint()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 331, in entrypoint\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._status_reporter.get_checkpoint())\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/util/tracing/tracing_helper.py\", line 451, in _resume_span\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     return method(self, *_args, **_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 600, in _trainable_func\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     output = fn()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/utils/trainable.py\", line 371, in inner\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     trainable(config, **fn_kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"<ipython-input-54-9c98fcb13069>\", line 25, in train_feyn_tune\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 741, in fit\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 685, in _call_and_handle_interrupt\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     return trainer_fn(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 777, in _fit_impl\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._run(model, ckpt_path=ckpt_path)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1199, in _run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._dispatch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1279, in _dispatch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.training_type_plugin.start_training(self)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._results = trainer.run_stage()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1289, in run_stage\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     return self._run_train()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1311, in _run_train\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._run_sanity_check(self.lightning_module)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1375, in _run_sanity_check\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._evaluation_loop.run()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.advance(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 110, in advance\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/base.py\", line 140, in run\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py\", line 86, in on_run_start\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._dataloader_iter = _update_dataloader_iter(data_fetcher, self.batch_progress.current.ready)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/utilities.py\", line 121, in _update_dataloader_iter\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     dataloader_iter = enumerate(data_fetcher, batch_idx)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 199, in __iter__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self.prefetching(self.prefetch_batches)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 258, in prefetching\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     self._fetch_next_batch()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/fetching.py\", line 300, in _fetch_next_batch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     batch = next(self.dataloader_iter)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data = self._next_data()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     return self._process_data(data)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data.reraise()\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     raise exception\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m TypeError: Caught TypeError in DataLoader worker process 0.\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m Original Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data = fetcher.fetch(index)\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m     data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m   File \"<ipython-input-44-711c8f04ffdb>\", line 10, in __getitem__\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m TypeError: 'FeynmanDataset' object is not subscriptable\n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_feyn_tune_ba3ed_00007:\n",
            "  date: 2022-03-10_16-04-56\n",
            "  experiment_id: 11a545c9c9dc443fb2b745a65bebedc1\n",
            "  hostname: 5fbc48a868f9\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 1493\n",
            "  timestamp: 1646928296\n",
            "  trial_id: ba3ed_00007\n",
            "  \n",
            "\u001b[2m\u001b[36m(train_feyn_tune pid=1493)\u001b[0m \rValidation sanity check: 0it [00:00, ?it/s]\rValidation sanity check:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "== Status ==\n",
            "Current time: 2022-03-10 16:05:01 (running for 00:00:48.29)\n",
            "Memory usage on this node: 3.2/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
            "Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/6.24 GiB heap, 0.0/3.12 GiB objects\n",
            "Result logdir: /root/ray_results/tune_mnist_asha\n",
            "Number of trials: 10/10 (8 ERROR, 2 PENDING)\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "| Trial name                  | status   | loc             |   model_batch_size |   model_weight_decay |   model_learning_rate |   model_embedding_size |   model_attention_heads |   model_layers |   model_dropout_rate |   model_top_k_ratio |   model_top_k_every_n |   model_dense_neurons |   model_edge_dim |   model_lin_dropout_prob |\n",
            "|-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------|\n",
            "| train_feyn_tune_ba3ed_00008 | PENDING  |                 |                 64 |                1e-06 |           0.0038311   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00009 | PENDING  |                 |                 64 |                1e-06 |           0.0254437   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00000 | ERROR    | 172.28.0.2:1155 |                 64 |                1e-06 |           0.00138708  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00001 | ERROR    | 172.28.0.2:1154 |                 64 |                1e-06 |           0.0178741   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00002 | ERROR    | 172.28.0.2:1276 |                 64 |                1e-06 |           0.00163658  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00003 | ERROR    | 172.28.0.2:1304 |                 64 |                1e-06 |           0.0551493   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00004 | ERROR    | 172.28.0.2:1354 |                 64 |                1e-06 |           0.0002585   |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00005 | ERROR    | 172.28.0.2:1398 |                 64 |                1e-06 |           0.000105566 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00006 | ERROR    | 172.28.0.2:1460 |                 64 |                1e-06 |           0.00143247  |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "| train_feyn_tune_ba3ed_00007 | ERROR    | 172.28.0.2:1493 |                 64 |                1e-06 |           0.000377635 |                      4 |                       4 |              3 |                  0.5 |                 0.2 |                     1 |                     4 |               11 |                      0.3 |\n",
            "+-----------------------------+----------+-----------------+--------------------+----------------------+-----------------------+------------------------+-------------------------+----------------+----------------------+---------------------+-----------------------+-----------------------+------------------+--------------------------+\n",
            "Number of errored trials: 8\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  |   # failures | error file                                                                                                                                                                                         |\n",
            "|-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| train_feyn_tune_ba3ed_00000 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00000_0_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-12/error.txt |\n",
            "| train_feyn_tune_ba3ed_00001 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00001_1_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00002 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00002_2_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-17/error.txt |\n",
            "| train_feyn_tune_ba3ed_00003 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00003_3_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-27/error.txt |\n",
            "| train_feyn_tune_ba3ed_00004 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00004_4_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-30/error.txt |\n",
            "| train_feyn_tune_ba3ed_00005 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00005_5_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-39/error.txt |\n",
            "| train_feyn_tune_ba3ed_00006 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00006_6_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-42/error.txt |\n",
            "| train_feyn_tune_ba3ed_00007 |            1 | /root/ray_results/tune_mnist_asha/train_feyn_tune_ba3ed_00007_7_model_attention_heads=4,model_batch_size=64,model_dense_neurons=4,model_dropout_rate=0.5,model_edge__2022-03-10_16-04-49/error.txt |\n",
            "+-----------------------------+--------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OofGr3KQK5_"
      },
      "source": [
        "#**Predict with last model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpDjmLP_QKKf"
      },
      "outputs": [],
      "source": [
        "#out = trainer.predict(model, dataloaders=pred_loader)\n",
        "#print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3qsIG0cRYfp"
      },
      "source": [
        "#**TensorBoard Logs and running training**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02-ZYDwvRbpn"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/gdrive/MyDrive/Part_III_Project/saved_models/lightning_logs"
      ]
    }
  ]
}