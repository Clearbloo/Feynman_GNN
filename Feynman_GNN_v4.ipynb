{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Clearbloo/Feynman_GNN/blob/main/Feynman_GNN_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZspqC4GXb_h-"
      },
      "source": [
        "#**Install and import libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "bmUsOZpbqF1W",
        "outputId": "0acc5ce1-d2af-4d0c-8e9a-ded9c2091d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2993973ea185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmakedirs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import os.path as osp\n",
        "import json\n",
        "import math\n",
        "import numpy as np \n",
        "import time\n",
        "from time import time, ctime\n",
        "import pandas as pd\n",
        "import ast\n",
        "from typing import Optional\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, f1_score, \\\n",
        "    accuracy_score, precision_score, recall_score, roc_auc_score\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "import copy\n",
        "import os.path as osp\n",
        "import re\n",
        "import sys\n",
        "import warnings\n",
        "from collections.abc import Sequence\n",
        "from typing import Any, Callable, List, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch.utils.data\n",
        "from torch import Tensor\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data.makedirs import makedirs\n",
        "\n",
        "IndexType = Union[slice, Tensor, np.ndarray, Sequence]\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from torch.nn import MSELoss\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default.\n",
        "    !pip install pytorch-lightning>=1.4\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "## Ray\n",
        "try:\n",
        "    import ray\n",
        "except ModuleNotFoundError: # Google Colab does not have Ray installed by default.\n",
        "    !pip install ray\n",
        "    import ray\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
        "from ray.tune.integration.pytorch_lightning import TuneReportCallback, TuneReportCheckpointCallback\n",
        "\n",
        "## Tensorboard\n",
        "try:\n",
        "  import tensorboardX\n",
        "except ModuleNotFoundError:\n",
        "  !pip install tensorboardX\n",
        "  import tensorboardX\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"/content/gdrive/MyDrive/Part_III_Project/data/\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"/content/gdrive/MyDrive/Part_III_Project/saved_models/\"\n",
        "\n",
        "# Setting the seed\n",
        "pl.seed_everything()\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.determinstic = False #True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "# torch geometric\n",
        "try: \n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version. \n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details \n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install --quiet torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install --quiet torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install --quiet torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install --quiet torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install --quiet torch-geometric \n",
        "    import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data\n",
        "from torch_geometric.data import Dataset, Data, InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
        "from torch_geometric.nn import TopKPooling \n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGUB_wlSthxj"
      },
      "source": [
        "#**My own dataset class**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myDataset(torch.utils.data.Dataset):\n",
        "    r\"\"\"Dataset base class for creating graph datasets.\n",
        "    See `here <https://pytorch-geometric.readthedocs.io/en/latest/notes/\n",
        "    create_dataset.html>`__ for the accompanying tutorial.\n",
        "\n",
        "    Args:\n",
        "        root (string, optional): Root directory where the dataset should be\n",
        "            saved. (optional: :obj:`None`)\n",
        "        transform (callable, optional): A function/transform that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
        "            version. The data object will be transformed before every access.\n",
        "            (default: :obj:`None`)\n",
        "        pre_transform (callable, optional): A function/transform that takes in\n",
        "            an :obj:`torch_geometric.data.Data` object and returns a\n",
        "            transformed version. The data object will be transformed before\n",
        "            being saved to disk. (default: :obj:`None`)\n",
        "        pre_filter (callable, optional): A function that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a boolean\n",
        "            value, indicating whether the data object should be included in the\n",
        "            final dataset. (default: :obj:`None`)\n",
        "    \"\"\"\n",
        "    @property\n",
        "    def raw_file_names(self) -> Union[str, List[str], Tuple]:\n",
        "        r\"\"\"The name of the files in the :obj:`self.raw_dir` folder that must\n",
        "        be present in order to skip downloading.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self) -> Union[str, List[str], Tuple]:\n",
        "        r\"\"\"The name of the files in the :obj:`self.processed_dir` folder that\n",
        "        must be present in order to skip processing.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def download(self):\n",
        "        r\"\"\"Downloads the dataset to the :obj:`self.raw_dir` folder.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def process(self):\n",
        "        r\"\"\"Processes the dataset to the :obj:`self.processed_dir` folder.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def len(self) -> int:\n",
        "        r\"\"\"Returns the number of graphs stored in the dataset.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def get(self, idx: int) -> Data:\n",
        "        r\"\"\"Gets the data object at index :obj:`idx`.\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def __init__(self, root: Optional[str] = None,\n",
        "                 transform: Optional[Callable] = None,\n",
        "                 pre_transform: Optional[Callable] = None,\n",
        "                 pre_filter: Optional[Callable] = None):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(root, str):\n",
        "            root = osp.expanduser(osp.normpath(root))\n",
        "\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.pre_filter = pre_filter\n",
        "        self._indices: Optional[Sequence] = None\n",
        "\n",
        "        if 'download' in self.__class__.__dict__:\n",
        "            self._download()\n",
        "\n",
        "        if 'process' in self.__class__.__dict__:\n",
        "            self._process()\n",
        "\n",
        "    def indices(self) -> Sequence:\n",
        "        return range(self.len()) if self._indices is None else self._indices\n",
        "\n",
        "    @property\n",
        "    def raw_dir(self) -> str:\n",
        "        return osp.join(self.root, 'raw')\n",
        "\n",
        "    @property\n",
        "    def processed_dir(self) -> str:\n",
        "        return osp.join(self.root, 'processed')\n",
        "\n",
        "    @property\n",
        "    def num_node_features(self) -> int:\n",
        "        r\"\"\"Returns the number of features per node in the dataset.\"\"\"\n",
        "        data = self[0]\n",
        "        data = data[0] if isinstance(data, tuple) else data\n",
        "        if hasattr(data, 'num_node_features'):\n",
        "            return data.num_node_features\n",
        "        raise AttributeError(f\"'{data.__class__.__name__}' object has no \"\n",
        "                             f\"attribute 'num_node_features'\")\n",
        "\n",
        "    @property\n",
        "    def num_features(self) -> int:\n",
        "        r\"\"\"Returns the number of features per node in the dataset.\n",
        "        Alias for :py:attr:`~num_node_features`.\"\"\"\n",
        "        return self.num_node_features\n",
        "\n",
        "    @property\n",
        "    def num_edge_features(self) -> int:\n",
        "        r\"\"\"Returns the number of features per edge in the dataset.\"\"\"\n",
        "        data = self[0]\n",
        "        data = data[0] if isinstance(data, tuple) else data\n",
        "        if hasattr(data, 'num_edge_features'):\n",
        "            return data.num_edge_features\n",
        "        raise AttributeError(f\"'{data.__class__.__name__}' object has no \"\n",
        "                             f\"attribute 'num_edge_features'\")\n",
        "\n",
        "    @property\n",
        "    def raw_paths(self) -> List[str]:\n",
        "        r\"\"\"The absolute filepaths that must be present in order to skip\n",
        "        downloading.\"\"\"\n",
        "        files = to_list(self.raw_file_names)\n",
        "        return [osp.join(self.raw_dir, f) for f in files]\n",
        "\n",
        "    @property\n",
        "    def processed_paths(self) -> List[str]:\n",
        "        r\"\"\"The absolute filepaths that must be present in order to skip\n",
        "        processing.\"\"\"\n",
        "        files = to_list(self.processed_file_names)\n",
        "        return [osp.join(self.processed_dir, f) for f in files]\n",
        "\n",
        "    def _download(self):\n",
        "        if files_exist(self.raw_paths):  # pragma: no cover\n",
        "            return\n",
        "\n",
        "        makedirs(self.raw_dir)\n",
        "        self.download()\n",
        "\n",
        "    def _process(self):\n",
        "        f = osp.join(self.processed_dir, 'pre_transform.pt')\n",
        "        if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
        "            warnings.warn(\n",
        "                f\"The `pre_transform` argument differs from the one used in \"\n",
        "                f\"the pre-processed version of this dataset. If you want to \"\n",
        "                f\"make use of another pre-processing technique, make sure to \"\n",
        "                f\"sure to delete '{self.processed_dir}' first\")\n",
        "\n",
        "        f = osp.join(self.processed_dir, 'pre_filter.pt')\n",
        "        if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
        "            warnings.warn(\n",
        "                \"The `pre_filter` argument differs from the one used in the \"\n",
        "                \"pre-processed version of this dataset. If you want to make \"\n",
        "                \"use of another pre-fitering technique, make sure to delete \"\n",
        "                \"'{self.processed_dir}' first\")\n",
        "\n",
        "        if files_exist(self.processed_paths):  # pragma: no cover\n",
        "            return\n",
        "\n",
        "        print('Processing...', file=sys.stderr)\n",
        "\n",
        "        makedirs(self.processed_dir)\n",
        "        self.process()\n",
        "\n",
        "        path = osp.join(self.processed_dir, 'pre_transform.pt')\n",
        "        torch.save(_repr(self.pre_transform), path)\n",
        "        path = osp.join(self.processed_dir, 'pre_filter.pt')\n",
        "        torch.save(_repr(self.pre_filter), path)\n",
        "\n",
        "        print('Done!', file=sys.stderr)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        r\"\"\"The number of examples in the dataset.\"\"\"\n",
        "        return len(self.indices())\n",
        "\n",
        "    def __getitem__(\n",
        "        self,\n",
        "        idx: Union[int, np.integer, IndexType],\n",
        "    ) -> Union['Dataset', Data]:\n",
        "        r\"\"\"In case :obj:`idx` is of type integer, will return the data object\n",
        "        at index :obj:`idx` (and transforms it in case :obj:`transform` is\n",
        "        present).\n",
        "        In case :obj:`idx` is a slicing object, *e.g.*, :obj:`[2:5]`, a list, a\n",
        "        tuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type long or\n",
        "        bool, will return a subset of the dataset at the specified indices.\"\"\"\n",
        "        if (isinstance(idx, (int, np.integer))\n",
        "                or (isinstance(idx, Tensor) and idx.dim() == 0)\n",
        "                or (isinstance(idx, np.ndarray) and np.isscalar(idx))):\n",
        "\n",
        "            data = self.get(self.indices()[idx])\n",
        "            data = data if self.transform is None else self.transform(data)\n",
        "            return data\n",
        "\n",
        "        else:\n",
        "            return self.index_select(idx)\n",
        "\n",
        "    def index_select(self, idx: IndexType) -> 'Dataset':\n",
        "        r\"\"\"Creates a subset of the dataset from specified indices :obj:`idx`.\n",
        "        Indices :obj:`idx` can be a slicing object, *e.g.*, :obj:`[2:5]`, a\n",
        "        list, a tuple, or a :obj:`torch.Tensor` or :obj:`np.ndarray` of type\n",
        "        long or bool.\"\"\"\n",
        "        indices = self.indices()\n",
        "\n",
        "        if isinstance(idx, slice):\n",
        "            indices = indices[idx]\n",
        "\n",
        "        elif isinstance(idx, Tensor) and idx.dtype == torch.long:\n",
        "            return self.index_select(idx.flatten().tolist())\n",
        "\n",
        "        elif isinstance(idx, Tensor) and idx.dtype == torch.bool:\n",
        "            idx = idx.flatten().nonzero(as_tuple=False)\n",
        "            return self.index_select(idx.flatten().tolist())\n",
        "\n",
        "        elif isinstance(idx, np.ndarray) and idx.dtype == np.int64:\n",
        "            return self.index_select(idx.flatten().tolist())\n",
        "\n",
        "        elif isinstance(idx, np.ndarray) and idx.dtype == np.bool:\n",
        "            idx = idx.flatten().nonzero()[0]\n",
        "            return self.index_select(idx.flatten().tolist())\n",
        "\n",
        "        elif isinstance(idx, Sequence) and not isinstance(idx, str):\n",
        "            indices = [indices[i] for i in idx]\n",
        "\n",
        "        else:\n",
        "            raise IndexError(\n",
        "                f\"Only slices (':'), list, tuples, torch.tensor and \"\n",
        "                f\"np.ndarray of dtype long or bool are valid indices (got \"\n",
        "                f\"'{type(idx).__name__}')\")\n",
        "\n",
        "        dataset = copy.copy(self)\n",
        "        dataset._indices = indices\n",
        "        return dataset\n",
        "\n",
        "\n",
        "    def shuffle(\n",
        "        self,\n",
        "        return_perm: bool = False,\n",
        "    ) -> Union['Dataset', Tuple['Dataset', Tensor]]:\n",
        "        r\"\"\"Randomly shuffles the examples in the dataset.\n",
        "\n",
        "        Args:\n",
        "            return_perm (bool, optional): If set to :obj:`True`, will also\n",
        "                return the random permutation used to shuffle the dataset.\n",
        "                (default: :obj:`False`)\n",
        "        \"\"\"\n",
        "        perm = torch.randperm(len(self))\n",
        "        dataset = self.index_select(perm)\n",
        "        return (dataset, perm) if return_perm is True else dataset\n",
        "\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        arg_repr = str(len(self)) if len(self) > 1 else ''\n",
        "        return f'{self.__class__.__name__}({arg_repr})'\n",
        "\n",
        "\n",
        "\n",
        "def to_list(value: Any) -> Sequence:\n",
        "    if isinstance(value, Sequence) and not isinstance(value, str):\n",
        "        return value\n",
        "    else:\n",
        "        return [value]\n",
        "\n",
        "\n",
        "def files_exist(files: List[str]) -> bool:\n",
        "    # NOTE: We return `False` in case `files` is empty, leading to a\n",
        "    # re-processing of files on every instantiation.\n",
        "    return len(files) != 0 and all([osp.exists(f) for f in files])\n",
        "\n",
        "\n",
        "def _repr(obj: Any) -> str:\n",
        "    if obj is None:\n",
        "        return 'None'\n",
        "    return re.sub('(<.*?)\\\\s.*(>)', r'\\1\\2', obj.__repr__())"
      ],
      "metadata": {
        "id": "HX_eVxydMCmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Fl5qXWH9Hp7"
      },
      "outputs": [],
      "source": [
        "class FeynmanDataset(myDataset):\n",
        "    def __init__(self, dataset_size, filename, reprocess: bool = False, root=DATASET_PATH, test: bool = False, train: bool = False, val: bool = False, pred: bool = False, transform=None, pre_transform=None, pre_filter=None):\n",
        "      #print(args)\n",
        "      #print(kwargs)\n",
        "      #print(self.__class__)\n",
        "      \"\"\"\n",
        "      root = directory where dataset should be stored. Contains raw data in raw_dir and processed data in processed_dir\n",
        "      test, train, val = bools, what type of dataset you want. default all false\n",
        "      \"\"\"\n",
        "      self.filename = filename\n",
        "      self.test = test \n",
        "      self.train = train\n",
        "      self.val = val\n",
        "      self.pred = pred\n",
        "      self.reproc = reprocess\n",
        "      self.label=\"\"\n",
        "      if self.train == True:\n",
        "        self.label=\"train\"\n",
        "      if self.val == True:\n",
        "        self.label=\"val\"\n",
        "      if self.test == True:\n",
        "        self.label=\"test\"\n",
        "      if self.pred == True:\n",
        "        self.label=\"pred\"\n",
        "      \n",
        "      self.dataset_size = dataset_size\n",
        "      super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "      #skips download if this is found\n",
        "      return self.filename\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "      #will skip the process method if the following files are found\n",
        "      proc_files = []\n",
        "      for idx in range(self.dataset_size):\n",
        "        proc_files +=  [f'{self.label}_data_{idx}.pt']\n",
        "      return proc_files\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`. In the future I will make this call a python file to build the dataset as a csv\n",
        "        print(\"No files to download\")\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "      self.data = pd.read_csv(self.raw_paths[0])\n",
        "      self.data = self.data.sample(n=self.dataset_size)\n",
        "\n",
        "      \n",
        "      #create a list of all y values\n",
        "      all_y_values = []\n",
        "      for row, feyndiag in self.data.iterrows():\n",
        "        y = self._get_targets(feyndiag)\n",
        "        all_y_values += [y]\n",
        "      \n",
        "      #cycle through graphs and create data objects for each\n",
        "      idx=0\n",
        "      print(\"Saving Data objects\")\n",
        "      for row, feyndiag in tqdm(self.data.iterrows(), total=self.data.shape[0]):\n",
        "        \n",
        "        #node features\n",
        "        x = self._get_node_features(feyndiag)\n",
        "        #edge features\n",
        "        edge_attr = self._get_edge_features(feyndiag)\n",
        "        #adjacency list\n",
        "        edge_index = self._get_adj_list(feyndiag)\n",
        "        #targets\n",
        "        y = self._get_targets(feyndiag)\n",
        "        #normalized targets to the interval [0,1]\n",
        "        y_norm = (y-min(all_y_values))/(max(all_y_values)-min(all_y_values))\n",
        "\n",
        "\n",
        "        #create data object\n",
        "        data = Data(x=x, edge_index = edge_index, edge_attr=edge_attr, y=y, y_norm=y_norm)\n",
        "        \n",
        "        #save file\n",
        "        torch.save(data, osp.join(self.processed_dir, f'{self.label}_data_{idx}.pt'))\n",
        "        idx+=1\n",
        "      \n",
        "\n",
        "    def _get_node_features(self, diagram):\n",
        "      \"\"\"\n",
        "      This will return a list of the node feature vectors (which are 1D)\n",
        "      [Number of Nodes, 1]\n",
        "      \"\"\"\n",
        "      x = ast.literal_eval(diagram.loc['x'])\n",
        "      x = torch.tensor(x,dtype=torch.float).view(-1,1)\n",
        "      return x\n",
        "\n",
        "    def _get_edge_features(self, diagram):\n",
        "      \"\"\"\n",
        "      This will return a list of the edge feature vectors (which are 11D)\n",
        "      [Number of Edges, 11]\n",
        "      \"\"\"\n",
        "      attr = ast.literal_eval(diagram.loc['edge_attr'])\n",
        "      return torch.tensor(attr,dtype=torch.float).view(-1,11)\n",
        "      \n",
        "    def _get_adj_list(self, diagram):\n",
        "      \"\"\"\n",
        "      This will return a list of the adjacency vectors (which are 2D)\n",
        "      [2, Number of Edges]\n",
        "      \"\"\"\n",
        "      adj_list = ast.literal_eval(diagram.loc['edge_index'])\n",
        "      return torch.tensor(adj_list,dtype=torch.long).view(2,-1)\n",
        "\n",
        "    def _get_targets(self, diagram):\n",
        "      \"\"\"\n",
        "      This will return a list of the target vectors (which are 1D)\n",
        "      [Number of targets, 1]\n",
        "      \"\"\"\n",
        "      y = diagram.loc['y']\n",
        "      return torch.tensor(y,dtype=torch.float)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(osp.join(self.processed_dir, f'{self.label}_data_{idx}.pt'))\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZotGXzouB-Dj"
      },
      "source": [
        "#**Loss functions**\n",
        "Defining some loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zWEkVjjB5Yr"
      },
      "outputs": [],
      "source": [
        "class LogCoshLoss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, y_t, y_prime_t):\n",
        "        ey_t = y_t - y_prime_t\n",
        "        return torch.mean(torch.log(torch.cosh(ey_t + 1e-12)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXS1oepDgkfR"
      },
      "outputs": [],
      "source": [
        "class RMSLELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        \n",
        "    def forward(self, pred, actual):\n",
        "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYNUWQmkBq47"
      },
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "    \n",
        "    def forward(self, pred, actual):\n",
        "      return torch.sqrt(self.mse(pred, actual))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK86ybzgev1g"
      },
      "source": [
        "#**Training code and GNN model using Lightning Module**\n",
        "\n",
        "* Lightning training module\n",
        "* Uses Transformer convolution layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDgx_mD0XzKk"
      },
      "outputs": [],
      "source": [
        "class FeynModel(pl.LightningModule):\n",
        "    def __init__(self, c_in, c_out, layer_name, model_params, data_dir=DATASET_PATH, filename='QED_data.csv'):\n",
        "        \"\"\"\n",
        "        c_in = channels in (feature dimensions, e.g. RGB is 3)\n",
        "        c_out = channels out (target dimension, e.g. classification is 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.data_dir=data_dir\n",
        "        self.filename=filename\n",
        "        self.batch_size = model_params[\"model_batch_size\"]\n",
        "        embedding_size = model_params[\"model_embedding_size\"]\n",
        "        n_heads = model_params[\"model_attention_heads\"]\n",
        "        self.n_layers = model_params[\"model_layers\"]\n",
        "        dropout_rate = model_params[\"model_dropout_rate\"]\n",
        "        top_k_ratio =  model_params[\"model_top_k_ratio\"]\n",
        "        self.top_k_every_n = model_params[\"model_top_k_every_n\"]\n",
        "        dense_neurons = model_params[\"model_dense_neurons\"]\n",
        "        edge_dim = model_params[\"model_edge_dim\"]-3 #remove momenta from edge_attr\n",
        "        edge_num = 5 #need to update this\n",
        "                \n",
        "        gnn_layer = gnn_layer_by_name[layer_name]\n",
        "        self.lr = model_params[\"model_learning_rate\"]\n",
        "        self.weight_decay = model_params[\"model_weight_decay\"]\n",
        "        self.lin_dropout_prob = model_params[\"model_lin_dropout_prob\"]\n",
        "        self.save_hyperparameters()\n",
        "        self.loss_fn = MSELoss()\n",
        "\n",
        "        self.conv_layers = ModuleList([])\n",
        "        self.transf_layers = ModuleList([])\n",
        "        self.pooling_layers = ModuleList([])\n",
        "        self.bn_layers = ModuleList([])\n",
        "\n",
        "        # Transformation layer\n",
        "        self.conv1 = gnn_layer(in_channels=c_in,\n",
        "                               out_channels=embedding_size, \n",
        "                               heads=n_heads, \n",
        "                               dropout=dropout_rate,\n",
        "                               edge_dim=edge_dim\n",
        "                               ) \n",
        "\n",
        "        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
        "        self.bn1 = BatchNorm1d(embedding_size)\n",
        "\n",
        "        # Other layers\n",
        "        for i in range(self.n_layers):\n",
        "            self.conv_layers.append(gnn_layer(embedding_size, \n",
        "                                              embedding_size, \n",
        "                                              heads=n_heads, \n",
        "                                              dropout=dropout_rate,\n",
        "                                              edge_dim=edge_dim,\n",
        "                                              ))\n",
        "\n",
        "            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
        "            self.bn_layers.append(BatchNorm1d(embedding_size))\n",
        "            if i % self.top_k_every_n == 0:\n",
        "                self.pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n",
        "            \n",
        "\n",
        "        # Linear layers\n",
        "        self.linear0 = Linear(embedding_size*2+3*2*edge_num, embedding_size*2)\n",
        "        self.linear1 = Linear((embedding_size)*2, dense_neurons)\n",
        "        self.linear2 = Linear(dense_neurons, c_out)\n",
        "\n",
        "        \"\"\"\n",
        "        could use super node instead of topKPooling an linear layers\n",
        "        or more topK pooling rather than linear layers\n",
        "        \"\"\"\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch_index):\n",
        "        # Remove momenta from edge features\n",
        "        p = edge_attr[:,8:11]\n",
        "        p = p.reshape(max(batch_index)+1,-1)\n",
        "        edge_attr = edge_attr[:,0:8]\n",
        "\n",
        "        # Initial transformation\n",
        "        x = self.conv1(x, edge_index, edge_attr)\n",
        "        x = F.leaky_relu(self.transf1(x))\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        # Holds the intermediate graph representations\n",
        "        global_representation = []\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            x = self.conv_layers[i](x, edge_index, edge_attr)\n",
        "            x = F.leaky_relu(self.transf_layers[i](x))\n",
        "            x = self.bn_layers[i](x)\n",
        "            # Always aggregate last layer\n",
        "            if i % self.top_k_every_n == 0 or i == self.n_layers:\n",
        "                x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](\n",
        "                    x, edge_index, edge_attr, batch_index\n",
        "                    )\n",
        "                # Add current representation\n",
        "                global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
        "    \n",
        "        x = sum(global_representation)\n",
        "\n",
        "        #add momenta on\n",
        "        x = torch.cat((x,p),1)\n",
        "\n",
        "        # Output block\n",
        "        x = F.leaky_relu(self.linear0(x))\n",
        "        x = F.dropout(x,p=self.lin_dropout_prob, training=self.training)\n",
        "        x = F.leaky_relu(self.linear1(x))\n",
        "        x = F.dropout(x, p=self.lin_dropout_prob, training=self.training)\n",
        "        x = torch.sigmoid(self.linear2(x))\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, edge_index, edge_attr, y = batch['x'], batch['edge_index'], batch['edge_attr'], batch['y_norm']\n",
        "        batch_idx = batch['batch']\n",
        "        y_hat = self(x,\n",
        "                     edge_index,\n",
        "                     edge_attr,\n",
        "                     batch_idx\n",
        "        )\n",
        "        loss = self.loss_fn(y_hat, y.view(-1,1))\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=False, batch_size=max(batch_idx)+1)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, edge_index, edge_attr, y = batch['x'], batch['edge_index'], batch['edge_attr'], batch['y_norm']\n",
        "        batch_idx = batch['batch']\n",
        "        y_hat = self(x,\n",
        "                     edge_index,\n",
        "                     edge_attr,\n",
        "                     batch_idx\n",
        "        )\n",
        "        loss = self.loss_fn(y_hat, y.view(-1,1))\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True, batch_size=max(batch_idx)+1)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, edge_index, edge_attr, y = batch['x'], batch['edge_index'], batch['edge_attr'], batch['y_norm']\n",
        "        batch_idx = batch['batch']\n",
        "        y_hat = self(x,\n",
        "                     edge_index,\n",
        "                     edge_attr,\n",
        "                     batch_idx)\n",
        "        loss = self.loss_fn(y_hat, y.view(-1,1))\n",
        "        self.log(\"test_loss\", loss, prog_bar=True, on_step=True, on_epoch=False, batch_size=max(batch_idx)+1)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        x, edge_index, edge_attr, y = batch['x'], batch['edge_index'], batch['edge_attr'], batch['y_norm']\n",
        "        batch_idx = batch['batch']\n",
        "        y_hat = self(x,\n",
        "                     edge_index,\n",
        "                     edge_attr,\n",
        "                     batch_idx)\n",
        "        return y_hat.item(), y.item()\n",
        "\n",
        "    def prepare_data(self):\n",
        "      print(\"No data to prepare\") \n",
        "\n",
        "    def setup(self, stage: Optional[str]) -> None:\n",
        "      #def prepare_data(self):\n",
        "    #def setup(self, *args, **kwargs):\n",
        "      #print(args)\n",
        "      #print(kwargs)\n",
        "      \"\"\"\n",
        "      I should edit this data to make the y values more uniformly distributed across the range\n",
        "      \"\"\"\n",
        "      print(\"Loading datasets...\")\n",
        "      self.train_dataset = FeynmanDataset(100000, reprocess=False, root=self.data_dir, filename=self.filename, train=True)\n",
        "      self.test_dataset = FeynmanDataset(10000, reprocess=False, root=self.data_dir, filename=self.filename, test=True)\n",
        "      self.val_dataset = FeynmanDataset(50000, reprocess=False, root=self.data_dir, filename=self.filename, val=True)\n",
        "      self.pred_dataset = FeynmanDataset(100, reprocess=False, root=self.data_dir, filename=self.filename, pred=True)\n",
        "      print(\"Finished all!\")\n",
        "      #return super().setup(stage=stage)\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(dataset=self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "      return DataLoader(dataset=self.val_dataset, batch_size=self.batch_size, num_workers=2)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "      return DataLoader(dataset=self.test_dataset, batch_size=self.batch_size, num_workers=2)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(dataset=self.pred_dataset, batch_size=1) #keep this batch_size as one to get predictions to work\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(),\n",
        "                                lr=self.lr,\n",
        "                                weight_decay=self.weight_decay,\n",
        "                                )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLopbX9b_spV"
      },
      "source": [
        "#**Tuning the hyperparameters with Ray Tune**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDfp1TeIASgI"
      },
      "outputs": [],
      "source": [
        "def train_feyn_no_tune(params, num_gpus, num_epochs=10):\n",
        "  \"\"\"\n",
        "  Function to train the Feynman GNN without a hyperparameter search.\n",
        "  params = The hyperparameters to use, stored as a dictionary with the notation \"model_...\"\n",
        "  \"\"\"\n",
        "  #need to make layer type a hyperparameter\n",
        "  model_params = {k: v[0] for k, v in params.items() if k.startswith(\"model_\")}\n",
        "  model = FeynModel(c_in=-1, #train_dataset.num_node_features \n",
        "                    c_out=1,  #train_dataset.num_classes\n",
        "                    layer_name=\"GAT\",\n",
        "                    model_params=model_params,\n",
        "                    #filename=\n",
        "                    )\n",
        "  trainer = pl.Trainer(logger=TensorBoardLogger(CHECKPOINT_PATH, name=\"saved_model\"),\n",
        "                       max_epochs=num_epochs,\n",
        "                       gpus=math.ceil(num_gpus),\n",
        "                       log_every_n_steps=10,\n",
        "                       #progress_bar_refresh_rate=0,\n",
        "                       callbacks=[EarlyStopping('val_loss',patience=10)],\n",
        "                       )\n",
        "  trainer.fit(model)\n",
        "  trainer.validate(model)\n",
        "  trainer.test(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySMx4x_0X6rM"
      },
      "outputs": [],
      "source": [
        "def train_feyn_tune(config, num_epochs=10, num_gpus=0):\n",
        "  \"\"\"\n",
        "  function to run a training run that will be called later by the tuning function\n",
        "  \"\"\"\n",
        "  model = FeynModel(c_in=-1, #train_dataset.num_node_features \n",
        "                    c_out=1,  #train_dataset.num_classes\n",
        "                    layer_name=\"GAT\",\n",
        "                    model_params=config,\n",
        "                    #filename=\n",
        "                    )\n",
        "  trainer = pl.Trainer(logger=TensorBoardLogger(save_dir=tune.get_trial_dir(),\n",
        "                                                name=\"\",\n",
        "                                                version=\".\"),\n",
        "                       max_epochs=num_epochs,\n",
        "                       gpus=math.ceil(num_gpus),\n",
        "                       log_every_n_steps=10,\n",
        "                       #progress_bar_refresh_rate=0,\n",
        "                       callbacks=[TuneReportCallback({\"loss\": \"val_loss\",   \n",
        "                                                      #\"mean_accuracy\": \"val_acc\"\n",
        "                                                      },\n",
        "                                                     on=\"validation_end\"),\n",
        "                                  #EarlyStopping('val_loss',patience=10)\n",
        "                                  ]\n",
        "                       )\n",
        "  trainer.fit(model)\n",
        "\n",
        "def tune_feyn_asha(config, gpus_per_trial=0, num_epochs=10, num_samples=10):\n",
        "\n",
        "    scheduler = ASHAScheduler(\n",
        "        max_t=num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "\n",
        "    reporter = CLIReporter(\n",
        "        parameter_columns=[\n",
        "                           \"model_batch_size\",\n",
        "                           \"model_weight_decay\",\n",
        "                           \"model_learning_rate\",\n",
        "                           \"model_embedding_size\",\n",
        "                           \"model_attention_heads\",\n",
        "                           \"model_layers\",\n",
        "                           \"model_dropout_rate\",\n",
        "                           \"model_top_k_ratio\",\n",
        "                           \"model_top_k_every_n\",\n",
        "                           \"model_dense_neurons\",\n",
        "                           \"model_edge_dim\",\n",
        "                           \"model_lin_dropout_prob\"],\n",
        "        metric_columns=[\"loss\", \"training_iteration\"])\n",
        "\n",
        "    train_fn_with_parameters = tune.with_parameters(train_feyn_tune,\n",
        "                                                    num_epochs=num_epochs,\n",
        "                                                    num_gpus=gpus_per_trial,\n",
        "                                                    )\n",
        "    \n",
        "    resources_per_trial = {\"cpu\": 1, \"gpu\": gpus_per_trial}\n",
        "\n",
        "    analysis = tune.run(train_fn_with_parameters,\n",
        "        resources_per_trial=resources_per_trial,\n",
        "        metric=\"loss\",\n",
        "        mode=\"min\",\n",
        "        config=config,\n",
        "        num_samples=num_samples,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter,\n",
        "        name=\"tune_mnist_asha\")\n",
        "\n",
        "    print(\"Best hyperparameters found were: \", analysis.best_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oZGz9gpDFdT"
      },
      "source": [
        "#**Create layer dictionary and Hyperparameters**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aw_Cv-GPPRxY"
      },
      "outputs": [],
      "source": [
        "#layer name dictionary\n",
        "gnn_layer_by_name = {\n",
        "    \"GCN\": geom_nn.GCNConv,\n",
        "    \"GAT\": geom_nn.GATConv,\n",
        "    \"GraphConv\": geom_nn.GraphConv,\n",
        "    \"NNConv\": geom_nn.NNConv,\n",
        "    \"RGCN\": geom_nn.RGCNConv,\n",
        "    \"Trans\": geom_nn.TransformerConv\n",
        "}\n",
        "\n",
        "#Hyperparameters to use if not tuning\n",
        "HYPERPARAMETERS = {\n",
        "    \"model_batch_size\": [64],\n",
        "    \"model_weight_decay\": [0.000001],\n",
        "    \"model_learning_rate\": [0.01],\n",
        "    \"model_embedding_size\": [128],\n",
        "    \"model_attention_heads\": [4],\n",
        "    \"model_layers\": [5],\n",
        "    \"model_dropout_rate\": [0.5],\n",
        "    \"model_top_k_ratio\": [0.2],\n",
        "    \"model_top_k_every_n\": [1],\n",
        "    \"model_dense_neurons\": [4],\n",
        "    \"model_edge_dim\": [11],\n",
        "    \"model_lin_dropout_prob\": [0.3],\n",
        "    }\n",
        "\n",
        "#Hyperparameters for ray tune to search through\n",
        "config = {\n",
        "    \"model_batch_size\": tune.choice([64]),\n",
        "    \"model_weight_decay\": tune.choice([0.000001]),\n",
        "    \"model_learning_rate\": tune.loguniform(0.0001,0.1),\n",
        "    \"model_embedding_size\": tune.choice([4]),\n",
        "    \"model_attention_heads\": tune.choice([4]),\n",
        "    \"model_layers\": tune.choice([3]),\n",
        "    \"model_dropout_rate\": tune.choice([0.5]),\n",
        "    \"model_top_k_ratio\": tune.choice([0.2]),\n",
        "    \"model_top_k_every_n\": tune.choice([1]),\n",
        "    \"model_dense_neurons\": tune.choice([4]),\n",
        "    \"model_edge_dim\": tune.choice([11]),\n",
        "    \"model_lin_dropout_prob\": tune.choice([0.3]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQFzsPHBBJzP"
      },
      "outputs": [],
      "source": [
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "print(f\"Torch geometric version: {torch_geometric.__version__}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  gpus=1\n",
        "else:\n",
        "  gpus=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OF1U2nVMDbc"
      },
      "outputs": [],
      "source": [
        "train_feyn_no_tune(HYPERPARAMETERS,gpus,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlxllxPBQKuS"
      },
      "outputs": [],
      "source": [
        "tune_feyn_asha(config, gpus_per_trial=gpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OofGr3KQK5_"
      },
      "source": [
        "#**Predict with last model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpDjmLP_QKKf"
      },
      "outputs": [],
      "source": [
        "out = trainer.predict(model, dataloaders=pred_loader)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3qsIG0cRYfp"
      },
      "source": [
        "#**TensorBoard Logs and running training**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02-ZYDwvRbpn"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/gdrive/MyDrive/Part_III_Project/saved_models/lightning_logs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Feynman_GNN_v4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1RYlvSUb702zRoG2vnqoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}